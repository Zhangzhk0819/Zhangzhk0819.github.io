<!DOCTYPE html >
<html> 
  <head> 
    <title>LMSanitator</title>
    <link rel="stylesheet" href="./css/css"/>
    <link rel="stylesheet" href="./css/iconize.css"/>
    <link rel="stylesheet" href="./css/project.css"/>
    <script src="https://code.jquery.com/jquery-3.1.0.min.js"> </script>
  </head>
  <body> 
    <div id="content"> 
      <div id="content-inner"> 
        <div class="section head">
          <h1><a href="https://arxiv.org/abs/2308.13904">LMSanitator: Defending Task-agnostic Backdoors Against Prompt-tuning</a></h1>
          <h2><a href="https://www.ndss-symposium.org/ndss2024/">NDSS 2024</a></h2>
          <div class="authors"><a href="">Chengkun Wei</a><sup>1</sup>
            <tab></tab><a href="">Wenlong Meng</a><sup>1</sup>
            <tab></tab><a href="http://zhangzhk.com/">Zhikun Zhang</a><sup>2</sup>
            <tab></tab><a href="https://milkigit.github.io/">Min Chen</a><sup>2</sup>
            <tab></tab><a href="">Minghu Zhao</a><sup>1</sup>
            <tab></tab><a href="">Wenjing Fang</a><sup>3</sup>
            <tab></tab><a href="">Lei Wang</a><sup>3</sup>
            <tab></tab><a href="">Zihui Zhang</a><sup>1</sup>
            <tab></tab><a href="">Wenzhi Chen</a><sup>1</sup>
            <tab></tab>
            <div class="affiliations"></div>
            <p>1. Zhejiang University 2. CISPA Helmholtz Center for Information Security 3. Ant Group </p>
          </div>
        </div>
        <div class="framework"> 
          <center><img src="./projects/LMSanitator/overview.png" width="90%"/></center>
        </div>
        <div class="section abstract"> 
          <h2>Abstract</h2><br/>
          <p>Prompt-tuning has emerged as an attractive paradigm for deploying large-scale language models due to its strong downstream task performance and efficient multitask serving ability. Despite its wide adoption, we empirically show that prompt-tuning is vulnerable to downstream task-agnostic backdoors, which reside in the pretrained models and can affect arbitrary downstream tasks. The state-of-the-art backdoor detection approaches cannot defend against task-agnostic backdoors since they hardly converge in reversing the backdoor triggers. To address this issue, we propose LMSanitator, a novel approach for detecting and removing task-agnostic backdoors on Transformer models. Instead of directly inverting the triggers, LMSanitator aims to invert the predefined attack vectors (pretrained models' output when the input is embedded with triggers) of the task-agnostic backdoors, which achieves much better convergence performance and backdoor detection accuracy. LMSanitator further leverages prompt-tuningâ€™s property of freezing the pretrained model to perform accurate and fast output monitoring and input purging during the inference phase. Extensive experiments on multiple language models and NLP tasks illustrate the effectiveness of LMSanitator. For instance, LMSanitator achieves 92.8% backdoor detection accuracy on 960 models and decreases the attack success rate to less than 1% in most scenarios.</p>
        </div>
        <div class="section info"> 
          <h2>Resources </h2><br/>
          <div class="res-collection"> 
            <div class="col"><a class="res-link" href="./projects/LMSanitator/LMSanitator.pdf"><img class="res-img" src="./img/PDF_logo.jpeg"/></a></div>
            <div class="col"><a class="res-link" href="https://arxiv.org/abs/2308.13904"><img class="res-img" src="./img/ArXiv_logo.png"/></a></div>
            <div class="col"><a class="res-link" href="https://github.com/meng-wenlong/LMSanitator"><img class="res-img" src="./img/GitHub_logo.jpeg"/></a></div>
            <div class="col"><img class="res-img" src="./img/PPT_logo.webp"/></div>
            <div class="col"><img class="res-img" src="./img/YouTube_logo.jpeg"/></div>
            <div class="col"><img class="res-img" src="./img/WeChat_logo.jpeg"/></div>
          </div>
        </div>
        <div class="section citation"> 
          <h2>Citation </h2>
          <div class="section bibtex"> 
            <pre> @inproceedings{WMZCZFWZC24,
    author = {Chengkun Wei and Wenlong Meng and Zhikun Zhang and Min Chen and Minghu Zhao and Wenjing Fang and Lei Wang and Zihui Zhang and Wenzhi Chen},
    title = {{LMSanitator: Defending Task-agnostic Backdoors Against Prompt-tuning}},
    booktitle = {{NDSS}},
    publisher = {},
    year = {2024},
}</pre>
          </div>
        </div>
      </div>
    </div>
    <script src="./js/script.js"> </script>
  </body>
</html>