<!DOCTYPE html >
<html> 
  <head> 
    <title>ORL-Auditor</title>
    <link rel="stylesheet" href="./css/css"/>
    <link rel="stylesheet" href="./css/iconize.css"/>
    <link rel="stylesheet" href="./css/project.css"/>
    <script src="https://code.jquery.com/jquery-3.1.0.min.js"> </script>
  </head>
  <body> 
    <div id="content"> 
      <div id="content-inner"> 
        <div class="section head">
          <h1><a href="https://arxiv.org/abs/2309.03081">ORL-Auditor: Dataset Auditing in Offline Deep Reinforcement Learning</a></h1>
          <h2><a href="https://www.ndss-symposium.org/ndss2024/">NDSS 2024</a></h2>
          <div class="authors"><a href="https://www.linkangd.info/">Linkang Du</a><sup>1</sup>
            <tab></tab><a href="https://milkigit.github.io/">Min Chen</a><sup>2</sup>
            <tab></tab><a href="https://0-scholar-google-com.brum.beds.ac.uk/citations?user=Vq9aHxoAAAAJ&amp;hl=nl">Mingyang Sun</a><sup>1</sup>
            <tab></tab><a href="https://nesa.zju.edu.cn/webpage/crew/jsl.html">Shouling Ji</a><sup>1</sup>
            <tab></tab><a href="https://person.zju.edu.cn/en/cp">Peng Cheng</a><sup>1</sup>
            <tab></tab><a href="https://person.zju.edu.cn/en/jmchen">Jiming Chen</a><sup>1</sup>
            <tab></tab><a href="http://zhangzhk.com/">Zhikun Zhang</a><sup>2</sup>
            <tab></tab>
            <div class="affiliations"></div>
            <p>1. Zhejiang University 2. CISPA Helmholtz Center for Information Security </p>
          </div>
        </div>
        <div class="framework"> 
          <center><img src="./projects/ORL-Auditor/overview.png" width="90%"/></center>
        </div>
        <div class="section abstract"> 
          <h2>Abstract</h2><br/>
          <p>Data is a critical asset in AI, as high-quality datasets can significantly improve the performance of machine learning models. In safety-critical domains such as autonomous vehicles, offline deep reinforcement learning (offline DRL) is frequently used to train models on pre-collected datasets, as opposed to training these models by interacting with the real-world environment as the online DRL. To support the development of these models, many institutions make datasets publicly available with opensource licenses, but these datasets are at risk of potential misuse or infringement. Injecting watermarks to the dataset may protect the intellectual property of the data, but it cannot handle datasets that have already been published and is infeasible to be altered afterward. Other existing solutions, such as dataset inference and membership inference, do not work well in the offline DRL scenario due to the diverse model behavior characteristics and offline setting constraints. In this paper, we advocate a new paradigm by leveraging the fact that cumulative rewards can act as a unique identifier that distinguishes DRL models trained on a specific dataset. To this end, we propose ORL-AUDITOR, which is the first trajectorylevel dataset auditing mechanism for offline RL scenarios. Our experiments on multiple offline DRL models and tasks reveal the efficacy of ORL-AUDITOR, with auditing accuracy over 95% and false positive rates less than 2.88%. We also provide valuable insights into the practical implementation of ORL-AUDITOR by studying various parameter settings. Furthermore, we demonstrate the auditing capability of ORL-AUDITOR on open-source datasets from Google and DeepMind, highlighting its effectiveness in auditing published datasets. ORL-AUDITOR is open-sourced at https://github.com/link-zju/ORL-Auditor.</p>
        </div>
        <div class="section info"> 
          <h2>Resources </h2><br/>
          <div class="res-collection"> 
            <div class="col"><a class="res-link" href="./projects/ORL-Auditor/ORL-Auditor.pdf"><img class="res-img" src="./img/PDF_logo.jpeg"/></a></div>
            <div class="col"><a class="res-link" href="https://arxiv.org/abs/2309.03081"><img class="res-img" src="./img/ArXiv_logo.png"/></a></div>
            <div class="col"><a class="res-link" href="https://github.com/link-zju/ORL-Auditor"><img class="res-img" src="./img/GitHub_logo.jpeg"/></a></div>
            <div class="col"><img class="res-img" src="./img/PPT_logo.webp"/></div>
            <div class="col"><img class="res-img" src="./img/YouTube_logo.jpeg"/></div>
            <div class="col"><img class="res-img" src="./img/WeChat_logo.jpeg"/></div>
          </div>
        </div>
        <div class="section citation"> 
          <h2>Citation </h2>
          <div class="section bibtex"> 
            <pre> @inproceedings{DCSJCCZ24,
    author = {Linkang Du and Min Chen and Mingyang Sun and Shouling Ji and Peng Cheng and Jiming Chen and Zhikun Zhang},
    title = {{ORL-Auditor: Dataset Auditing in Offline Deep Reinforcement Learning}},
    booktitle = {{NDSS}},
    publisher = {},
    year = {2024},
}</pre>
          </div>
        </div>
      </div>
    </div>
    <script src="./js/script.js"> </script>
  </body>
</html>